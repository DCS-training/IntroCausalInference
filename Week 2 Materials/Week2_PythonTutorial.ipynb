{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Gentle Introduction to Causal Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the second python tutorial for the Gentle Introduction to Causal Inference course with the CDCS. In this script you will use your python skills to employ causal inference in practice. For this we will be using the 'palmer penguins' dataset. More information can be found about this data set here: https://allisonhorst.github.io/palmerpenguins/index.html. For time purposes we will use the csv version of this file from the github.\n",
    "\n",
    "In this exercise, we will explore whether **species type (Adelie vs. other species) has an effect on flipper length** in penguins. The idea is to estimate whether belonging to the **Adelie species** causally influences flipper length, while accounting for potential confounding factors such as **bill length, bill depth, body mass, and other morphological characteristics**.\n",
    "\n",
    "This mirrors real-world studies in **ecology and social sciences**, where researchers investigate whether an exposure (e.g., policy, education, or a biological factor) has a causal impact on an outcome. However, in observational data, individuals (or penguins in this case!) are **not randomly assigned** to species groups, which means **confounding** may be present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 0\n",
    "We're going to go ahead and load in the same data we used last week. Additionally we will import a range of packages. There is a comment next to each one. Briefly discuss what we use each package for in your group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                     # IMPORT FOR: Data Handling\n",
    "import numpy as np                                      # IMPORT FOR: Numerical Calculations          \n",
    "import seaborn as sns                                   # IMPORT FOR: Data Visualisation\n",
    "import matplotlib.pyplot as plt                         # IMPORT FOR: Data Visualisation\n",
    "from sklearn.linear_model import LogisticRegression     # IMPORT FOR: Propensity Scoring\n",
    "from sklearn.utils import resample                      # IMPORT FOR: Matching\n",
    "import statsmodels.api as sm                            # IMPORT FOR: Estimation\n",
    "from statsmodels.formula.api import ols                 # IMPORT FOR: Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and drop missing values for simplicity\n",
    "penguins = pd.read_csv(\"palmer_penguins.csv\")\n",
    "penguins = penguins.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "For being able to conduct our propensity scores we need a binary variable 'treatment' to work with. This simply means our independent variable (exposure) needs to be binary. Go ahead and create a species binary variable which encodes the Adelie species as 1 and Chinstrap/Gentoo as 0. Call this 'treated'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "We're now going to estimate our propensity scores. Select the following as covariates: 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', and 'body_mass_g'. Then run the logistic regression below to estimate our propensity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = [INSERT COVARIATES HERE]\n",
    "logit = LogisticRegression()\n",
    "logit.fit(penguins[covariates], penguins['treated'])\n",
    "penguins['propensity_score'] = logit.predict_proba(penguins[covariates])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "When we estimate propesity scoring it is useful for us to visualise how these scores are distributed throughout our dataset. Lets create a plot to help us to do this. Run the code below and discuss in below it what you see. In particular answer:\n",
    "\n",
    "i. Can we anticipate from this how much data we may need to remove?\n",
    "\n",
    "ii. Is there anything in between the two groups which may help us decide?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(penguins[penguins['treated'] == 1]['propensity_score'], label='Adelie', fill=True)\n",
    "sns.kdeplot(penguins[penguins['treated'] == 0]['propensity_score'], label='Other Species', fill=True)\n",
    "plt.title(\"Propensity Score Distribution by Species\")\n",
    "plt.xlabel(\"Propensity Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Now we need to perform some sort of matching. We want to do this based on the propensity scores. We can use **nearest-neighbour matching** based on propensity scores. We should then assess balance before and after matching. Discuss what happens after the matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treated = penguins[penguins['treated'] == 1]\n",
    "control = penguins[penguins['treated'] == 0]\n",
    "\n",
    "treated = treated.sort_values(\"propensity_score\")\n",
    "control = control.sort_values(\"propensity_score\")\n",
    "\n",
    "matched_control = control.iloc[np.argmin(np.abs(control['propensity_score'].values[:, None] - treated['propensity_score'].values), axis=0)]\n",
    "matched_data = pd.concat([treated, matched_control])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "sns.kdeplot(penguins[penguins['treated'] == 1]['propensity_score'], label='Adelie', ax=ax[0])\n",
    "sns.kdeplot(penguins[penguins['treated'] == 0]['propensity_score'], label='Other Species', ax=ax[0])\n",
    "ax[0].set_title('Before Matching')\n",
    "\n",
    "sns.kdeplot(matched_data[matched_data['treated'] == 1]['propensity_score'], label='Adelie', ax=ax[1])\n",
    "sns.kdeplot(matched_data[matched_data['treated'] == 0]['propensity_score'], label='Other Species', ax=ax[1])\n",
    "ax[1].set_title('After Matching')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Finally, even if it isn't looking too promising lets still retrieve an estimate using the matched data. Comment on this and the confidence interval that we see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_model = sm.OLS(matched_data['flipper_length_mm'], sm.add_constant(matched_data['treated'])).fit()\n",
    "matched_effect = matched_model.params.iloc[1]\n",
    "matched_ci = matched_model.conf_int().loc['treated']\n",
    "print(f\"Matched Treatment Effect Estimate: {matched_effect:.4f} ({matched_ci[0]:.4f}, {matched_ci[1]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "Now lets try to compute **IPTW weights** based on propensity scores and reweight the data to create a pseudo-randomised sample. Once again comment on the plot you seem, what can we tell about the potential success of our IPTW from the graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['iptw_weight'] = np.where(penguins['treated'] == 1, 1 / penguins['propensity_score'], 1 / (1 - penguins['propensity_score']))\n",
    "sns.histplot(penguins['iptw_weight'], bins=30, kde=True)\n",
    "plt.title(\"Distribution of IPTW Weights\")\n",
    "plt.xlabel(\"Weight Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "Our final task is to use the statsmodels weighted method to use IPTW to estimate the causal effect of being an Adelie penguin on flipper length. Run this and comment on the difference between the IPTW based estimate and the matched based estimate...something very interesting has occured and highlights the wider issue of confounding..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iptw_model = sm.WLS(\n",
    "    penguins['flipper_length_mm'],\n",
    "    sm.add_constant(penguins['treated']),\n",
    "    weights=penguins['iptw_weight']\n",
    ").fit()\n",
    "\n",
    "iptw_effect = iptw_model.params.iloc[1]\n",
    "iptw_ci = iptw_model.conf_int().loc['treated']\n",
    "print(f\"IPTW Treatment Effect Estimate: {iptw_effect:.4f} ({iptw_ci[0]:.4f}, {iptw_ci[1]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
